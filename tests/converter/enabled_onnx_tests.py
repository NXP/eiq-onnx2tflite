#
# Copyright 2023-2025 NXP
#
# License: LA_OPT_Online Code Hosting NXP_Software_License
# See the LICENSE for more details.
#
import pytest

from onnx2tflite.src import logger

COMPARISON_ARGS = "comparison_args"
CONVERSION_ARGS = "conversion_args"
CONVERSION_ERROR = "conversion_error"
CONVERSION_ERROR_NODE = "node"
CONVERSION_ERROR_ERROR = "error"
CONVERSION_ERROR_MSG = "message"


def get_error_dict(code: logger.Code, message: str, node_idx: int):
    return {
        CONVERSION_ERROR_NODE: node_idx,
        CONVERSION_ERROR_ERROR: code,
        CONVERSION_ERROR_MSG: f'[Code.{logger.Code(code).name}] - ' + message
    }


def conversion_impossible(message: str, node_idx: int = 0):
    return get_error_dict(logger.Code.CONVERSION_IMPOSSIBLE, message, node_idx)


def not_implemented(message: str, node_idx: int = 0):
    return get_error_dict(logger.Code.NOT_IMPLEMENTED, message, node_idx)


def internal_error(message: str, node_idx: int = 0):
    return get_error_dict(logger.Code.INTERNAL_ERROR, message, node_idx)


def invalid_onnx_operator(message: str, node_idx: int = 0):
    return get_error_dict(logger.Code.INVALID_ONNX_OPERATOR, message, node_idx)


NODE = {
    "test_abs": {},
    # "test_acos": {},
    # "test_acos_example": {},
    # "test_acosh": {},
    # "test_acosh_example": {},
    # "test_adagrad": {},
    # "test_adagrad_multiple": {},
    # "test_adam": {},
    # "test_adam_multiple": {},
    "test_add": {},
    "test_add_bcast": {},
    # "test_add_uint8": {},
    # "test_affine_grid_2d": {},
    # "test_affine_grid_2d_align_corners": {},
    # "test_affine_grid_2d_align_corners_expanded": {},
    # "test_affine_grid_2d_expanded": {},
    # "test_affine_grid_3d": {},
    # "test_affine_grid_3d_align_corners": {},
    # "test_affine_grid_3d_align_corners_expanded": {},
    # "test_affine_grid_3d_expanded": {},
    # "test_ai_onnx_ml_array_feature_extractor": {},
    # "test_ai_onnx_ml_binarizer": {},
    # "test_ai_onnx_ml_label_encoder_string_int": {},
    # "test_ai_onnx_ml_label_encoder_string_int_no_default": {},
    # "test_ai_onnx_ml_label_encoder_tensor_mapping": {},
    # "test_ai_onnx_ml_label_encoder_tensor_value_only_mapping": {},
    # "test_ai_onnx_ml_tree_ensemble_set_membership": {},
    # "test_ai_onnx_ml_tree_ensemble_single_tree": {},
    "test_and2d": {},
    "test_and3d": {},
    "test_and4d": {},
    "test_and_bcast3v1d": {},
    "test_and_bcast3v2d": {},
    "test_and_bcast4v2d": {},
    "test_and_bcast4v3d": {},
    "test_and_bcast4v4d": {},
    "test_argmax_default_axis_example": {},
    "test_argmax_default_axis_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_default_axis_random": {},
    "test_argmax_default_axis_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_keepdims_example": {},
    "test_argmax_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_keepdims_random": {},
    "test_argmax_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_negative_axis_keepdims_example": {},
    "test_argmax_negative_axis_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_negative_axis_keepdims_random": {},
    "test_argmax_negative_axis_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_no_keepdims_example": {},
    "test_argmax_no_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmax_no_keepdims_random": {},
    "test_argmax_no_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMax` with `select_last_index=1` is not possible.')},
    "test_argmin_default_axis_example": {},
    "test_argmin_default_axis_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_default_axis_random": {},
    "test_argmin_default_axis_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_keepdims_example": {},
    "test_argmin_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_keepdims_random": {},
    "test_argmin_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_negative_axis_keepdims_example": {},
    "test_argmin_negative_axis_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_negative_axis_keepdims_random": {},
    "test_argmin_negative_axis_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_no_keepdims_example": {},
    "test_argmin_no_keepdims_example_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    "test_argmin_no_keepdims_random": {},
    "test_argmin_no_keepdims_random_select_last_index": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of ONNX `ArgMin` with `select_last_index=1` is not possible.')},
    # "test_asin": {},
    # "test_asin_example": {},
    # "test_asinh": {},
    # "test_asinh_example": {},
    # "test_atan": {},
    # "test_atan_example": {},
    # "test_atanh": {},
    # "test_atanh_example": {},
    "test_averagepool_1d_default": {},
    "test_averagepool_2d_ceil": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX AveragePool with 'ceil_mode' = 1 and 'count_include_pad' = 0 is not possible.")},
    "test_averagepool_2d_default": {COMPARISON_ARGS: {"atol": 1e-7}},
    "test_averagepool_2d_dilations": {CONVERSION_ERROR: not_implemented(
        "Conversion of ONNX AveragePool with dilations '[2, 2]' is not yet implemented.")},
    "test_averagepool_2d_pads": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!")},
    "test_averagepool_2d_pads_count_include_pad": {COMPARISON_ARGS: {"atol": 1e-7}},
    "test_averagepool_2d_precomputed_pads": {},
    "test_averagepool_2d_precomputed_pads_count_include_pad": {},
    "test_averagepool_2d_precomputed_same_upper": {},
    "test_averagepool_2d_precomputed_strides": {},
    "test_averagepool_2d_same_lower": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!")},
    "test_averagepool_2d_same_upper": {COMPARISON_ARGS: {"atol": 1e-7}},
    "test_averagepool_2d_strides": {COMPARISON_ARGS: {"atol": 1e-7}},
    # "test_averagepool_3d_default": {},
    # "test_averagepool_3d_dilations_large_count_include_pad_is_0_ceil_mode_is_False": {},
    # "test_averagepool_3d_dilations_large_count_include_pad_is_0_ceil_mode_is_True": {},
    # "test_averagepool_3d_dilations_large_count_include_pad_is_1_ceil_mode_is_False": {},
    # "test_averagepool_3d_dilations_large_count_include_pad_is_1_ceil_mode_is_True": {},
    # "test_averagepool_3d_dilations_small": {},
    "test_basic_conv_with_padding": {},
    "test_basic_conv_without_padding": {},
    # "test_basic_deform_conv_with_padding": {},
    # "test_basic_deform_conv_without_padding": {},
    "test_batchnorm_epsilon": {},
    # "test_batchnorm_epsilon_training_mode": {},
    "test_batchnorm_example": {},
    # "test_batchnorm_example_training_mode": {},
    # "test_bernoulli": {},
    # "test_bernoulli_double": {},
    # "test_bernoulli_double_expanded": {},
    # "test_bernoulli_expanded": {},
    # "test_bernoulli_seed": {},
    # "test_bernoulli_seed_expanded": {},
    # "test_bitshift_left_uint8": {},
    # "test_bitshift_left_uint16": {},
    # "test_bitshift_left_uint32": {},
    # "test_bitshift_left_uint64": {},
    # "test_bitshift_right_uint8": {},
    # "test_bitshift_right_uint16": {},
    # "test_bitshift_right_uint32": {},
    # "test_bitshift_right_uint64": {},
    # "test_bitwise_and_i16_3d": {},
    # "test_bitwise_and_i32_2d": {},
    # "test_bitwise_and_ui8_bcast_4v3d": {},
    # "test_bitwise_and_ui64_bcast_3v1d": {},
    # "test_bitwise_not_2d": {},
    # "test_bitwise_not_3d": {},
    # "test_bitwise_not_4d": {},
    # "test_bitwise_or_i16_4d": {},
    # "test_bitwise_or_i32_2d": {},
    # "test_bitwise_or_ui8_bcast_4v3d": {},
    # "test_bitwise_or_ui64_bcast_3v1d": {},
    # "test_bitwise_xor_i16_3d": {},
    # "test_bitwise_xor_i32_2d": {},
    # "test_bitwise_xor_ui8_bcast_4v3d": {},
    # "test_bitwise_xor_ui64_bcast_3v1d": {},
    # "test_blackmanwindow": {},
    # "test_blackmanwindow_expanded": {},
    # "test_blackmanwindow_symmetric": {},
    # "test_blackmanwindow_symmetric_expanded": {},
    # "test_cast_BFLOAT16_to_FLOAT": {},
    "test_cast_DOUBLE_to_FLOAT": {},
    "test_cast_DOUBLE_to_FLOAT16": {},
    # "test_cast_FLOAT8E4M3FN_to_FLOAT": {},
    # "test_cast_FLOAT8E4M3FN_to_FLOAT16": {},
    # "test_cast_FLOAT8E4M3FNUZ_to_FLOAT": {},
    # "test_cast_FLOAT8E4M3FNUZ_to_FLOAT16": {},
    # "test_cast_FLOAT8E5M2_to_FLOAT": {},
    # "test_cast_FLOAT8E5M2_to_FLOAT16": {},
    # "test_cast_FLOAT8E5M2FNUZ_to_FLOAT": {},
    # "test_cast_FLOAT8E5M2FNUZ_to_FLOAT16": {},
    "test_cast_FLOAT16_to_DOUBLE": {},
    "test_cast_FLOAT16_to_FLOAT": {},
    # "test_cast_FLOAT16_to_FLOAT8E4M3FN": {},
    # "test_cast_FLOAT16_to_FLOAT8E4M3FNUZ": {},
    # "test_cast_FLOAT16_to_FLOAT8E5M2": {},
    # "test_cast_FLOAT16_to_FLOAT8E5M2FNUZ": {},
    # "test_cast_FLOAT16_to_INT4": {},
    # "test_cast_FLOAT16_to_UINT4": {},
    # "test_cast_FLOAT_to_BFLOAT16": {},
    "test_cast_FLOAT_to_DOUBLE": {},
    # "test_cast_FLOAT_to_FLOAT8E4M3FN": {},
    # "test_cast_FLOAT_to_FLOAT8E4M3FNUZ": {},
    # "test_cast_FLOAT_to_FLOAT8E5M2": {},
    # "test_cast_FLOAT_to_FLOAT8E5M2FNUZ": {},
    "test_cast_FLOAT_to_FLOAT16": {},
    # "test_cast_FLOAT_to_INT4": {},
    # "test_cast_FLOAT_to_STRING": {},
    # "test_cast_FLOAT_to_UINT4": {},
    # "test_cast_INT4_to_FLOAT": {},
    # "test_cast_INT4_to_FLOAT16": {},
    # "test_cast_INT4_to_INT8": {},
    # "test_cast_STRING_to_FLOAT": {},
    # "test_cast_UINT4_to_FLOAT": {},
    # "test_cast_UINT4_to_FLOAT16": {},
    # "test_cast_UINT4_to_UINT8": {},
    # "test_cast_no_saturate_FLOAT16_to_FLOAT8E4M3FN": {},
    # "test_cast_no_saturate_FLOAT16_to_FLOAT8E4M3FNUZ": {},
    # "test_cast_no_saturate_FLOAT16_to_FLOAT8E5M2": {},
    # "test_cast_no_saturate_FLOAT16_to_FLOAT8E5M2FNUZ": {},
    # "test_cast_no_saturate_FLOAT_to_FLOAT8E4M3FN": {},
    # "test_cast_no_saturate_FLOAT_to_FLOAT8E4M3FNUZ": {},
    # "test_cast_no_saturate_FLOAT_to_FLOAT8E5M2": {},
    # "test_cast_no_saturate_FLOAT_to_FLOAT8E5M2FNUZ": {},
    # "test_castlike_BFLOAT16_to_FLOAT": {},
    # "test_castlike_BFLOAT16_to_FLOAT_expanded": {},
    # "test_castlike_DOUBLE_to_FLOAT": {},
    # "test_castlike_DOUBLE_to_FLOAT16": {},
    "test_castlike_DOUBLE_to_FLOAT16_expanded": {},
    "test_castlike_DOUBLE_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT8E4M3FN_to_FLOAT": {},
    # "test_castlike_FLOAT8E4M3FN_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT8E4M3FNUZ_to_FLOAT": {},
    # "test_castlike_FLOAT8E4M3FNUZ_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT8E5M2_to_FLOAT": {},
    # "test_castlike_FLOAT8E5M2_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT8E5M2FNUZ_to_FLOAT": {},
    # "test_castlike_FLOAT8E5M2FNUZ_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT16_to_DOUBLE": {},
    "test_castlike_FLOAT16_to_DOUBLE_expanded": {},
    # "test_castlike_FLOAT16_to_FLOAT": {},
    "test_castlike_FLOAT16_to_FLOAT_expanded": {},
    # "test_castlike_FLOAT_to_BFLOAT16": {},
    # "test_castlike_FLOAT_to_BFLOAT16_expanded": {},
    # "test_castlike_FLOAT_to_DOUBLE": {},
    "test_castlike_FLOAT_to_DOUBLE_expanded": {},
    # "test_castlike_FLOAT_to_FLOAT8E4M3FN": {},
    # "test_castlike_FLOAT_to_FLOAT8E4M3FN_expanded": {},
    # "test_castlike_FLOAT_to_FLOAT8E4M3FNUZ": {},
    # "test_castlike_FLOAT_to_FLOAT8E4M3FNUZ_expanded": {},
    # "test_castlike_FLOAT_to_FLOAT8E5M2": {},
    # "test_castlike_FLOAT_to_FLOAT8E5M2_expanded": {},
    # "test_castlike_FLOAT_to_FLOAT8E5M2FNUZ": {},
    # "test_castlike_FLOAT_to_FLOAT8E5M2FNUZ_expanded": {},
    # "test_castlike_FLOAT_to_FLOAT16": {},
    "test_castlike_FLOAT_to_FLOAT16_expanded": {},
    # "test_castlike_FLOAT_to_STRING": {},
    # "test_castlike_FLOAT_to_STRING_expanded": {},
    # "test_castlike_STRING_to_FLOAT": {},
    # "test_castlike_STRING_to_FLOAT_expanded": {},
    "test_ceil": {},
    "test_ceil_example": {},
    # "test_celu": {},
    # "test_celu_expanded": {},
    # "test_center_crop_pad_crop": {},
    # "test_center_crop_pad_crop_and_pad": {},
    # "test_center_crop_pad_crop_and_pad_expanded": {},
    # "test_center_crop_pad_crop_axes_chw": {},
    # "test_center_crop_pad_crop_axes_chw_expanded": {},
    # "test_center_crop_pad_crop_axes_hwc": {},
    # "test_center_crop_pad_crop_axes_hwc_expanded": {},
    # "test_center_crop_pad_crop_expanded": {},
    # "test_center_crop_pad_crop_negative_axes_hwc": {},
    # "test_center_crop_pad_crop_negative_axes_hwc_expanded": {},
    # "test_center_crop_pad_pad": {},
    # "test_center_crop_pad_pad_expanded": {},
    "test_clip": {},
    "test_clip_default_inbounds": {},
    "test_clip_default_inbounds_expanded": {},  # Using 'Identity' instead of 'Clip'.
    "test_clip_default_int8_inbounds": {},
    "test_clip_default_int8_inbounds_expanded": {},  # Using 'Identity' instead of 'Clip'.
    "test_clip_default_int8_max": {},
    # "test_clip_default_int8_max_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_default_int8_min": {},
    # "test_clip_default_int8_min_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_default_max": {},
    "test_clip_default_max_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_default_min": {},
    "test_clip_default_min_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_example": {},
    "test_clip_example_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_inbounds": {},
    "test_clip_inbounds_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_outbounds": {},
    "test_clip_outbounds_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    "test_clip_splitbounds": {},
    "test_clip_splitbounds_expanded": {},  # Using 'Where' and 'Less' instead of 'Clip'.
    # "test_col2im": {},
    # "test_col2im_5d": {},
    # "test_col2im_dilations": {},
    # "test_col2im_pads": {},
    # "test_col2im_strides": {},
    # "test_compress_0": {},
    # "test_compress_1": {},
    # "test_compress_default_axis": {},
    # "test_compress_negative_axis": {},
    "test_concat_1d_axis_0": {},
    "test_concat_1d_axis_negative_1": {},
    "test_concat_2d_axis_0": {},
    "test_concat_2d_axis_1": {},
    "test_concat_2d_axis_negative_1": {},
    "test_concat_2d_axis_negative_2": {},
    "test_concat_3d_axis_0": {},
    "test_concat_3d_axis_1": {},
    "test_concat_3d_axis_2": {},
    "test_concat_3d_axis_negative_1": {},
    "test_concat_3d_axis_negative_2": {},
    "test_concat_3d_axis_negative_3": {},
    "test_constant": {},
    "test_constant_pad": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    "test_constant_pad_axes": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    "test_constant_pad_negative_axes": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    "test_constantofshape_float_ones": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_constantofshape_int_shape_zero": {},
    "test_constantofshape_int_zeros": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_conv_with_autopad_same": {},
    "test_conv_with_strides_and_asymmetric_padding": {},
    "test_conv_with_strides_no_padding": {},
    "test_conv_with_strides_padding": {},
    # "test_convinteger_with_padding": {},
    # "test_convinteger_without_padding": {},
    "test_convtranspose": {},
    # "test_convtranspose_1d": {},
    # "test_convtranspose_3d": {},
    "test_convtranspose_autopad_same": {},
    # "test_convtranspose_dilations": {},
    # "test_convtranspose_group_2": {},
    # "test_convtranspose_group_2_image_3": {},
    "test_convtranspose_kernel_shape": {},
    "test_convtranspose_output_shape": {},
    "test_convtranspose_pad": {},
    "test_convtranspose_pads": {},
    "test_cos": {},
    "test_cos_example": {},
    # "test_cosh": {},
    # "test_cosh_example": {},
    "test_cumsum_1d": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_1d_exclusive": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_1d_reverse": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_1d_reverse_exclusive": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_2d_axis_0": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_2d_axis_1": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    "test_cumsum_2d_negative_axis": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `CumSum` with type `FLOAT64`, is not possible.")},
    # "test_deform_conv_with_mask_bias": {},
    # "test_deform_conv_with_multiple_offset_groups": {},
    "test_depthtospace_crd_mode_example": {CONVERSION_ERROR: not_implemented(
        "Conversion of ONNX `DepthToSpace` with `mode=CRD` is not yet supported.")},
    "test_depthtospace_example": {},
    "test_dequantizelinear": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX 'DequantizeLinear' is only possible when the quantization parameters are static!")},
    "test_dequantizelinear_axis": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX 'DequantizeLinear' is only possible when the quantization parameters are static!")},
    # "test_dequantizelinear_blocked": {},
    "test_dequantizelinear_e4m3fn": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX 'DequantizeLinear' is only possible when the quantization parameters are static!")},
    # "test_dequantizelinear_e4m3fn_float16": {},
    # "test_dequantizelinear_e4m3fn_zero_point": {},
    "test_dequantizelinear_e5m2": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX 'DequantizeLinear' is only possible when the quantization parameters are static!")},
    # "test_dequantizelinear_int4": {},
    # "test_dequantizelinear_int16": {},
    # "test_dequantizelinear_uint4": {},
    # "test_dequantizelinear_uint16": {},
    # "test_det_2d": {},
    # "test_det_nd": {},
    # "test_dft": {},
    # "test_dft_axis": {},
    # "test_dft_axis_opset19": {},
    # "test_dft_inverse": {},
    # "test_dft_inverse_opset19": {},
    # "test_dft_opset19": {},
    "test_div": {},
    "test_div_bcast": {},
    "test_div_example": {},
    # "test_div_uint8": {},  # ONNXRT Not implemented in ONNX Runtime
    "test_dropout_default": {},
    "test_dropout_default_mask": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with more than 1 output is not possible.")},
    "test_dropout_default_mask_ratio": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with more than 1 output is not possible.")},
    "test_dropout_default_old": {},
    "test_dropout_default_ratio": {},
    "test_dropout_random_old": {},
    # "test_dynamicquantizelinear": {},
    # "test_dynamicquantizelinear_expanded": {},
    # "test_dynamicquantizelinear_max_adjusted": {},
    # "test_dynamicquantizelinear_max_adjusted_expanded": {},
    # "test_dynamicquantizelinear_min_adjusted": {},
    # "test_dynamicquantizelinear_min_adjusted_expanded": {},
    "test_edge_pad": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    "test_einsum_batch_diagonal": {CONVERSION_ARGS: {"allow_select_ops": True}, CONVERSION_ERROR: not_implemented(
        'Conversion of ONNX `Einsum` with ellipsis ("...") in the equation is not yet supported.')},
    "test_einsum_batch_matmul": {CONVERSION_ARGS: {"allow_select_ops": True}},
    "test_einsum_inner_prod": {CONVERSION_ARGS: {"allow_select_ops": True}},
    "test_einsum_sum": {CONVERSION_ARGS: {"allow_select_ops": True}},
    "test_einsum_transpose": {CONVERSION_ARGS: {"allow_select_ops": True}},
    "test_elu": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: not_implemented(
        'Conversion of ONNX `Elu` with `alpha=2.0` is not supported.')},
    "test_elu_default": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_elu_default_expanded_ver18": {},  # Expanded (CastLike...)
    "test_elu_example": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: not_implemented(
        'Conversion of ONNX `Elu` with `alpha=2.0` is not supported.')},
    # "test_elu_example_expanded_ver18": {},  # Expanded (CastLike...)
    # "test_elu_expanded_ver18": {},  # Expanded (CastLike...)
    "test_equal": {},
    "test_equal_bcast": {},
    "test_equal_string": {},
    "test_equal_string_broadcast": {},
    "test_erf": {CONVERSION_ARGS: {"allow_select_ops": True}},
    "test_exp": {},
    "test_exp_example": {},
    "test_expand_dim_changed": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_expand_dim_unchanged": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_eyelike_populate_off_main_diagonal": {},
    # "test_eyelike_with_dtype": {},
    # "test_eyelike_without_dtype": {},
    "test_flatten_axis0": {},
    "test_flatten_axis1": {},
    "test_flatten_axis2": {},
    "test_flatten_axis3": {},
    "test_flatten_default_axis": {},
    "test_flatten_negative_axis1": {},
    "test_flatten_negative_axis2": {},
    "test_flatten_negative_axis3": {},
    "test_flatten_negative_axis4": {},
    "test_floor": {},
    "test_floor_example": {},
    # "test_gather_0": {},
    # "test_gather_1": {},
    # "test_gather_2d_indices": {},
    # "test_gather_elements_0": {},
    # "test_gather_elements_1": {},
    # "test_gather_elements_negative_indices": {},
    # "test_gather_negative_indices": {},
    "test_gathernd_example_float32": {CONVERSION_ARGS: {"non_negative_indices": True}},
    "test_gathernd_example_int32": {CONVERSION_ARGS: {"non_negative_indices": True}},
    "test_gathernd_example_int32_batch_dim1": {
        CONVERSION_ARGS: {"non_negative_indices": True},
        CONVERSION_ERROR: conversion_impossible(
            'Conversion of ONNX `GatherND` with `batch_dims != 0` is not supported.')
    },
    "test_gelu_default_1": {},
    # "test_gelu_default_1_expanded": {},  # Doesn't use Gelu.
    "test_gelu_default_2": {COMPARISON_ARGS: {"atol": 2.4e-7}},
    # "test_gelu_default_2_expanded": {},  # Doesn't use Gelu.
    "test_gelu_tanh_1": {},
    # "test_gelu_tanh_1_expanded": {},  # Doesn't use Gelu.
    "test_gelu_tanh_2": {},
    # "test_gelu_tanh_2_expanded": {},  # Doesn't use Gelu.
    "test_gemm_all_attributes": {},
    "test_gemm_alpha": {},
    "test_gemm_beta": {},
    "test_gemm_default_matrix_bias": {},
    "test_gemm_default_no_bias": {},
    "test_gemm_default_scalar_bias": {},
    "test_gemm_default_single_elem_vector_bias": {},
    "test_gemm_default_vector_bias": {},
    "test_gemm_default_zero_bias": {},
    "test_gemm_transposeA": {},
    "test_gemm_transposeB": {},
    "test_globalaveragepool": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_globalaveragepool_precomputed": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_globalmaxpool": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_globalmaxpool_precomputed": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_greater": {},
    "test_greater_bcast": {},
    "test_greater_equal": {},
    "test_greater_equal_bcast": {},
    "test_greater_equal_bcast_expanded": {},
    "test_greater_equal_expanded": {},
    # "test_gridsample": {},
    # "test_gridsample_aligncorners_true": {},
    # "test_gridsample_bicubic": {},
    # "test_gridsample_bicubic_align_corners_0_additional_1": {},
    # "test_gridsample_bicubic_align_corners_1_additional_1": {},
    # "test_gridsample_bilinear": {},
    # "test_gridsample_bilinear_align_corners_0_additional_1": {},
    # "test_gridsample_bilinear_align_corners_1_additional_1": {},
    # "test_gridsample_border_padding": {},
    # "test_gridsample_nearest": {},
    # "test_gridsample_nearest_align_corners_0_additional_1": {},
    # "test_gridsample_nearest_align_corners_1_additional_1": {},
    # "test_gridsample_reflection_padding": {},
    # "test_gridsample_volumetric_bilinear_align_corners_0": {},
    # "test_gridsample_volumetric_bilinear_align_corners_1": {},
    # "test_gridsample_volumetric_nearest_align_corners_0": {},
    # "test_gridsample_volumetric_nearest_align_corners_1": {},
    # "test_gridsample_zeros_padding": {},
    # "test_group_normalization_epsilon": {},
    # "test_group_normalization_epsilon_expanded": {},
    # "test_group_normalization_example": {},
    # "test_group_normalization_example_expanded": {},
    # "test_gru_batchwise": {},
    # "test_gru_defaults": {},
    # "test_gru_seq_length": {},
    # "test_gru_with_initial_bias": {},
    # "test_hammingwindow": {},
    # "test_hammingwindow_expanded": {},
    # "test_hammingwindow_symmetric": {},
    # "test_hammingwindow_symmetric_expanded": {},
    # "test_hannwindow": {},
    # "test_hannwindow_expanded": {},
    # "test_hannwindow_symmetric": {},
    # "test_hannwindow_symmetric_expanded": {},
    # "test_hardmax_axis_0": {},
    # "test_hardmax_axis_1": {},
    # "test_hardmax_axis_2": {},
    # "test_hardmax_default_axis": {},
    # "test_hardmax_example": {},
    # "test_hardmax_negative_axis": {},
    # "test_hardmax_one_hot": {},
    "test_hardsigmoid": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_hardsigmoid_default": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_hardsigmoid_default_expanded_ver18": {},  # Uses CastLike, Add, Mul, Min and Max instead of HardSigmoid.
    "test_hardsigmoid_example": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_hardsigmoid_example_expanded_ver18": {},  # Uses CastLike, Add, Mul, Min and Max instead of HardSigmoid.
    # "test_hardsigmoid_expanded_ver18": {},  # Uses CastLike, Add, Mul, Min and Max instead of HardSigmoid.
    "test_hardswish": {},
    "test_hardswish_expanded": {},
    "test_identity": {},
    # "test_identity_opt": {},
    # "test_identity_sequence": {},
    # "test_if": {},
    # "test_if_opt": {},
    # "test_if_seq": {},
    # "test_image_decoder_decode_bmp_rgb": {},
    # "test_image_decoder_decode_jpeg2k_rgb": {},
    # "test_image_decoder_decode_jpeg_bgr": {},
    # "test_image_decoder_decode_jpeg_grayscale": {},
    # "test_image_decoder_decode_jpeg_rgb": {},
    # "test_image_decoder_decode_png_rgb": {},
    # "test_image_decoder_decode_pnm_rgb": {},
    # "test_image_decoder_decode_tiff_rgb": {},
    # "test_image_decoder_decode_webp_rgb": {},
    "test_instancenorm_epsilon": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_instancenorm_example": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_isinf": {},
    # "test_isinf_float16": {},
    # "test_isinf_negative": {},
    # "test_isinf_positive": {},
    # "test_isnan": {},
    # "test_isnan_float16": {},
    "test_layer_normalization_2d_axis0": {},
    # "test_layer_normalization_2d_axis0_expanded": {},
    # "test_layer_normalization_2d_axis0_expanded_ver18": {},
    "test_layer_normalization_2d_axis1": {},
    # "test_layer_normalization_2d_axis1_expanded": {},
    # "test_layer_normalization_2d_axis1_expanded_ver18": {},
    "test_layer_normalization_2d_axis_negative_1": {},
    # "test_layer_normalization_2d_axis_negative_1_expanded": {},
    # "test_layer_normalization_2d_axis_negative_1_expanded_ver18": {},
    "test_layer_normalization_2d_axis_negative_2": {},
    # "test_layer_normalization_2d_axis_negative_2_expanded": {},
    # "test_layer_normalization_2d_axis_negative_2_expanded_ver18": {},
    "test_layer_normalization_3d_axis0_epsilon": {},
    # "test_layer_normalization_3d_axis0_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis0_epsilon_expanded_ver18": {},
    "test_layer_normalization_3d_axis1_epsilon": {},
    # "test_layer_normalization_3d_axis1_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis1_epsilon_expanded_ver18": {},
    "test_layer_normalization_3d_axis2_epsilon": {},
    # "test_layer_normalization_3d_axis2_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis2_epsilon_expanded_ver18": {},
    "test_layer_normalization_3d_axis_negative_1_epsilon": {},
    # "test_layer_normalization_3d_axis_negative_1_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis_negative_1_epsilon_expanded_ver18": {},
    "test_layer_normalization_3d_axis_negative_2_epsilon": {},
    # "test_layer_normalization_3d_axis_negative_2_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis_negative_2_epsilon_expanded_ver18": {},
    "test_layer_normalization_3d_axis_negative_3_epsilon": {},
    # "test_layer_normalization_3d_axis_negative_3_epsilon_expanded": {},
    # "test_layer_normalization_3d_axis_negative_3_epsilon_expanded_ver18": {},
    "test_layer_normalization_4d_axis0": {},
    # "test_layer_normalization_4d_axis0_expanded": {},
    # "test_layer_normalization_4d_axis0_expanded_ver18": {},
    "test_layer_normalization_4d_axis1": {},
    # "test_layer_normalization_4d_axis1_expanded": {},
    # "test_layer_normalization_4d_axis1_expanded_ver18": {},
    "test_layer_normalization_4d_axis2": {},
    # "test_layer_normalization_4d_axis2_expanded": {},
    # "test_layer_normalization_4d_axis2_expanded_ver18": {},
    "test_layer_normalization_4d_axis3": {},
    # "test_layer_normalization_4d_axis3_expanded": {},
    # "test_layer_normalization_4d_axis3_expanded_ver18": {},
    "test_layer_normalization_4d_axis_negative_1": {COMPARISON_ARGS: {"atol": 1e-7}},
    # "test_layer_normalization_4d_axis_negative_1_expanded": {},
    # "test_layer_normalization_4d_axis_negative_1_expanded_ver18": {},
    "test_layer_normalization_4d_axis_negative_2": {},
    # "test_layer_normalization_4d_axis_negative_2_expanded": {},
    # "test_layer_normalization_4d_axis_negative_2_expanded_ver18": {},
    "test_layer_normalization_4d_axis_negative_3": {COMPARISON_ARGS: {"atol": 1e-7}},
    # "test_layer_normalization_4d_axis_negative_3_expanded": {},
    # "test_layer_normalization_4d_axis_negative_3_expanded_ver18": {},
    "test_layer_normalization_4d_axis_negative_4": {},
    # "test_layer_normalization_4d_axis_negative_4_expanded": {},
    # "test_layer_normalization_4d_axis_negative_4_expanded_ver18": {},
    "test_layer_normalization_default_axis": {},
    # "test_layer_normalization_default_axis_expanded": {},
    # "test_layer_normalization_default_axis_expanded_ver18": {},
    "test_leakyrelu": {},
    "test_leakyrelu_default": {},
    # "test_leakyrelu_default_expanded": {},
    "test_leakyrelu_example": {},
    # "test_leakyrelu_example_expanded": {},
    # "test_leakyrelu_expanded": {},
    "test_less": {},
    "test_less_bcast": {},
    "test_less_equal": {},
    "test_less_equal_bcast": {},
    # "test_less_equal_bcast_expanded": {},  # Uses 3 ops: `Less`, `Or`, `Equal`.
    # "test_less_equal_expanded": {},  # Uses 3 ops: `Less`, `Or`, `Equal`.
    "test_log": {},
    "test_log_example": {},
    "test_logsoftmax_axis_0": {},
    # "test_logsoftmax_axis_0_expanded": {},
    # "test_logsoftmax_axis_0_expanded_ver18": {},
    "test_logsoftmax_axis_1": {},
    # "test_logsoftmax_axis_1_expanded": {},
    # "test_logsoftmax_axis_1_expanded_ver18": {},
    "test_logsoftmax_axis_2": {},
    # "test_logsoftmax_axis_2_expanded": {},
    # "test_logsoftmax_axis_2_expanded_ver18": {},
    "test_logsoftmax_default_axis": {},
    # "test_logsoftmax_default_axis_expanded": {},
    # "test_logsoftmax_default_axis_expanded_ver18": {},
    "test_logsoftmax_example_1": {},
    # "test_logsoftmax_example_1_expanded": {},
    # "test_logsoftmax_example_1_expanded_ver18": {},
    "test_logsoftmax_large_number": {},
    # "test_logsoftmax_large_number_expanded": {},
    # "test_logsoftmax_large_number_expanded_ver18": {},
    "test_logsoftmax_negative_axis": {},
    # "test_logsoftmax_negative_axis_expanded": {},
    # "test_logsoftmax_negative_axis_expanded_ver18": {},
    # "test_loop11": {},
    # "test_loop13_seq": {},
    # "test_loop16_seq_none": {},
    # "test_lppool_1d_default": {},
    # "test_lppool_2d_default": {},
    # "test_lppool_2d_dilations": {},
    # "test_lppool_2d_pads": {},
    # "test_lppool_2d_same_lower": {},
    # "test_lppool_2d_same_upper": {},
    # "test_lppool_2d_strides": {},
    # "test_lppool_3d_default": {},
    "test_lrn": {},
    "test_lrn_default": {},
    # "test_lstm_batchwise": {},
    # "test_lstm_defaults": {},
    # "test_lstm_with_initial_bias": {},
    # "test_lstm_with_peepholes": {},
    "test_matmul_2d": {},
    "test_matmul_3d": {},
    "test_matmul_4d": {},
    # "test_matmulinteger": {},
    "test_max_example": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Max` with more than 2 inputs is not yet implemented.")},
    "test_max_float16": {
        CONVERSION_ERROR: conversion_impossible(
            "Conversion of the ONNX operator `Max` with type `FLOAT16`, is not possible.")},
    "test_max_float32": {},
    "test_max_float64": {
        CONVERSION_ERROR: conversion_impossible(
            "Conversion of the ONNX operator `Max` with type `FLOAT64`, is not possible.")},
    "test_max_int8": {
        CONVERSION_ERROR: not_implemented("Conversion of the ONNX operator `Max` with type `INT8`, is not supported.")},
    "test_max_int16": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Max` with type `INT16`, is not supported.")},
    "test_max_int32": {},
    "test_max_int64": {},
    "test_max_one_input": {},
    "test_max_two_inputs": {},
    "test_max_uint8": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Max` with type `UINT8`, is not supported.")},
    "test_max_uint16": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Max` with type `UINT16`, is not possible.")},
    "test_max_uint32": {
        CONVERSION_ERROR: conversion_impossible(
            "Conversion of the ONNX operator `Max` with type `UINT32`, is not possible.")},
    "test_max_uint64": {
        CONVERSION_ERROR: conversion_impossible(
            "Conversion of the ONNX operator `Max` with type `UINT64`, is not possible.")},
    "test_maxpool_1d_default": {},
    # "test_maxpool_2d_ceil": {},
    # "test_maxpool_2d_ceil_output_size_reduce_by_one": {},
    "test_maxpool_2d_default": {},
    # "test_maxpool_2d_dilations": {},
    "test_maxpool_2d_pads": {},
    "test_maxpool_2d_precomputed_pads": {},
    "test_maxpool_2d_precomputed_same_upper": {},
    "test_maxpool_2d_precomputed_strides": {},
    "test_maxpool_2d_same_lower": {},
    "test_maxpool_2d_same_upper": {},
    "test_maxpool_2d_strides": {},
    "test_maxpool_2d_uint8": {},
    # "test_maxpool_3d_default": {},
    # "test_maxpool_3d_dilations": {},
    # "test_maxpool_3d_dilations_use_ref_impl": {},
    # "test_maxpool_3d_dilations_use_ref_impl_large": {},
    # "test_maxpool_with_argmax_2d_precomputed_pads": {},
    # "test_maxpool_with_argmax_2d_precomputed_strides": {},
    # "test_maxunpool_export_with_output_shape": {},
    # "test_maxunpool_export_without_output_shape": {},
    # "test_mean_example": {},
    # "test_mean_one_input": {},
    # "test_mean_two_inputs": {},
    # "test_melweightmatrix": {},
    "test_min_example": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Min` with more than 2 inputs is not yet implemented.")},
    "test_min_float16": {
        CONVERSION_ERROR: conversion_impossible(
            "Conversion of the ONNX operator `Min` with type `FLOAT16`, is not possible.")},
    "test_min_float32": {},
    "test_min_float64": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Min` with type `FLOAT64`, is not possible.")},
    "test_min_int8": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Min` with type `INT8`, is not supported.")},
    "test_min_int16": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Min` with type `INT16`, is not supported.")},
    "test_min_int32": {},
    "test_min_int64": {},
    "test_min_one_input": {},
    "test_min_two_inputs": {},
    "test_min_uint8": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Min` with type `UINT8`, is not supported.")},
    "test_min_uint16": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Min` with type `UINT16`, is not possible.")},
    "test_min_uint32": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Min` with type `UINT32`, is not possible.")},
    "test_min_uint64": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Min` with type `UINT64`, is not possible.")},
    # "test_mish": {},
    # "test_mish_expanded": {},
    "test_mod_broadcast": {},
    "test_mod_int64_fmod": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `Mod` with `fmod=1` is not supported.')},
    "test_mod_mixed_sign_float16": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `Mod` with `fmod=1` is not supported.')},
    "test_mod_mixed_sign_float32": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `Mod` with `fmod=1` is not supported.')},
    "test_mod_mixed_sign_float64": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `Mod` with `fmod=1` is not supported.')},
    "test_mod_mixed_sign_int8": {
        CONVERSION_ERROR: not_implemented('Conversion of the ONNX operator `Mod` with type `INT8`, is not supported.')},
    "test_mod_mixed_sign_int16": {CONVERSION_ERROR: not_implemented(
        'Conversion of the ONNX operator `Mod` with type `INT16`, is not supported.')},
    "test_mod_mixed_sign_int32": {},
    "test_mod_mixed_sign_int64": {},
    "test_mod_uint8": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of the ONNX operator `Mod` with type `UINT8`, is not possible.')},
    "test_mod_uint16": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of the ONNX operator `Mod` with type `UINT16`, is not possible.')},
    "test_mod_uint32": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of the ONNX operator `Mod` with type `UINT32`, is not possible.')},
    "test_mod_uint64": {CONVERSION_ERROR: conversion_impossible(
        'Conversion of the ONNX operator `Mod` with type `UINT64`, is not possible.')},
    # "test_momentum": {},
    # "test_momentum_multiple": {},
    "test_mul": {},
    "test_mul_bcast": {},
    "test_mul_example": {},
    "test_mul_uint8": {CONVERSION_ERROR: not_implemented(
        "Conversion of the ONNX operator `Mul` with type `UINT8`, is not supported.")},
    # "test_mvn": {},
    "test_mvn_expanded": {},
    "test_mvn_expanded_ver18": {},
    "test_neg": {},
    "test_neg_example": {},
    # "test_nesterov_momentum": {},
    # "test_nllloss_NC": {},
    # "test_nllloss_NC_expanded": {},
    # "test_nllloss_NCd1": {},
    # "test_nllloss_NCd1_expanded": {},
    # "test_nllloss_NCd1_ii": {},
    # "test_nllloss_NCd1_ii_expanded": {},
    # "test_nllloss_NCd1_mean_weight_negative_ii": {},
    # "test_nllloss_NCd1_mean_weight_negative_ii_expanded": {},
    # "test_nllloss_NCd1_weight": {},
    # "test_nllloss_NCd1_weight_expanded": {},
    # "test_nllloss_NCd1_weight_ii": {},
    # "test_nllloss_NCd1_weight_ii_expanded": {},
    # "test_nllloss_NCd1d2": {},
    # "test_nllloss_NCd1d2_expanded": {},
    # "test_nllloss_NCd1d2_no_weight_reduction_mean_ii": {},
    # "test_nllloss_NCd1d2_no_weight_reduction_mean_ii_expanded": {},
    # "test_nllloss_NCd1d2_reduction_mean": {},
    # "test_nllloss_NCd1d2_reduction_mean_expanded": {},
    # "test_nllloss_NCd1d2_reduction_sum": {},
    # "test_nllloss_NCd1d2_reduction_sum_expanded": {},
    # "test_nllloss_NCd1d2_with_weight": {},
    # "test_nllloss_NCd1d2_with_weight_expanded": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_mean": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_mean_expanded": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_sum": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_sum_expanded": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_sum_ii": {},
    # "test_nllloss_NCd1d2_with_weight_reduction_sum_ii_expanded": {},
    # "test_nllloss_NCd1d2d3_none_no_weight_negative_ii": {},
    # "test_nllloss_NCd1d2d3_none_no_weight_negative_ii_expanded": {},
    # "test_nllloss_NCd1d2d3_sum_weight_high_ii": {},
    # "test_nllloss_NCd1d2d3_sum_weight_high_ii_expanded": {},
    # "test_nllloss_NCd1d2d3d4d5_mean_weight": {},
    # "test_nllloss_NCd1d2d3d4d5_mean_weight_expanded": {},
    # "test_nllloss_NCd1d2d3d4d5_none_no_weight": {},
    # "test_nllloss_NCd1d2d3d4d5_none_no_weight_expanded": {},
    # "test_nonmaxsuppression_center_point_box_format": {},
    # "test_nonmaxsuppression_flipped_coordinates": {},
    # "test_nonmaxsuppression_identical_boxes": {},
    # "test_nonmaxsuppression_limit_output_size": {},
    # "test_nonmaxsuppression_single_box": {},
    # "test_nonmaxsuppression_suppress_by_IOU": {},
    # "test_nonmaxsuppression_suppress_by_IOU_and_scores": {},
    # "test_nonmaxsuppression_two_batches": {},
    # "test_nonmaxsuppression_two_classes": {},
    # "test_nonzero_example": {},
    "test_not_2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_not_3d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_not_4d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_onehot_negative_indices": {CONVERSION_ARGS: {"skip_shape_inference": True, "non_negative_indices": True},
                                     CONVERSION_ERROR: not_implemented(
                                         "Conversion of ONNX `OneHot` with a dynamic `values` input is not yet supported.")},
    "test_onehot_with_axis": {CONVERSION_ARGS: {"skip_shape_inference": True, "non_negative_indices": True},
                              CONVERSION_ERROR: not_implemented(
                                  "Conversion of ONNX `OneHot` with a dynamic `values` input is not yet supported.")},
    "test_onehot_with_negative_axis": {CONVERSION_ARGS: {"skip_shape_inference": True, "non_negative_indices": True},
                                       CONVERSION_ERROR: not_implemented(
                                           "Conversion of ONNX `OneHot` with a dynamic `values` input is not yet supported.")},
    "test_onehot_without_axis": {CONVERSION_ARGS: {"skip_shape_inference": True, "non_negative_indices": True},
                                 CONVERSION_ERROR: not_implemented(
                                     "Conversion of ONNX `OneHot` with a dynamic `values` input is not yet supported.")},
    # "test_optional_get_element_optional_sequence": {},
    # "test_optional_get_element_optional_tensor": {},
    # "test_optional_get_element_sequence": {},
    # "test_optional_get_element_tensor": {},
    # "test_optional_has_element_empty_no_input_name_optional_input": {},
    # "test_optional_has_element_empty_no_input_name_tensor_input": {},
    # "test_optional_has_element_empty_no_input_optional_input": {},
    # "test_optional_has_element_empty_no_input_tensor_input": {},
    # "test_optional_has_element_empty_optional_input": {},
    # "test_optional_has_element_optional_input": {},
    # "test_optional_has_element_tensor_input": {},
    "test_or2d": {},
    "test_or3d": {},
    "test_or4d": {},
    "test_or_bcast3v1d": {},
    "test_or_bcast3v2d": {},
    "test_or_bcast4v2d": {},
    "test_or_bcast4v3d": {},
    "test_or_bcast4v4d": {},
    "test_pow": {},
    "test_pow_bcast_array": {},
    "test_pow_bcast_scalar": {},
    "test_pow_example": {},
    "test_pow_types_float32_int32": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_float32_int64": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_float32_uint32": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_float32_uint64": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_int32_float32": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_int32_int32": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Pow` with type `int32` and dynamic `power` input is not supported because the power values at runtime could be negative, which is not supported by TFLite.")},
    "test_pow_types_int64_float32": {
        CONVERSION_ERROR: not_implemented("Conversion of ONNX `Pow` with non-matching input types is not supported.")},
    "test_pow_types_int64_int64": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of the ONNX operator `Pow` with type `INT64`, is not possible.")},
    "test_prelu_broadcast": {},
    # "test_prelu_broadcast_expanded": {},
    "test_prelu_example": {},
    # "test_prelu_example_expanded": {},
    "test_qlinearconv": {CONVERSION_ERROR: not_implemented(
        "Conversion of ONNX quantized operators is only supported when the quantization parameters are static!")},
    # "test_qlinearmatmul_2D_int8_float16": {},
    # "test_qlinearmatmul_2D_int8_float32": {},
    # "test_qlinearmatmul_2D_uint8_float16": {},
    # "test_qlinearmatmul_2D_uint8_float32": {},
    # "test_qlinearmatmul_3D_int8_float16": {},
    # "test_qlinearmatmul_3D_int8_float32": {},
    # "test_qlinearmatmul_3D_uint8_float16": {},
    # "test_qlinearmatmul_3D_uint8_float32": {},
    # "test_quantizelinear": {},
    # "test_quantizelinear_axis": {},
    # "test_quantizelinear_blocked_asymmetric": {},
    # "test_quantizelinear_blocked_symmetric": {},
    # "test_quantizelinear_e4m3fn": {},
    # "test_quantizelinear_e5m2": {},
    # "test_quantizelinear_int4": {},
    # "test_quantizelinear_int16": {},
    # "test_quantizelinear_uint4": {},
    # "test_quantizelinear_uint16": {},
    # "test_range_float_type_positive_delta": {},
    # "test_range_float_type_positive_delta_expanded": {},
    # "test_range_int32_type_negative_delta": {},
    # "test_range_int32_type_negative_delta_expanded": {},
    "test_reciprocal": {},
    "test_reciprocal_example": {},
    # "test_reduce_l1_default_axes_keepdims_example": {},
    # "test_reduce_l1_default_axes_keepdims_example_expanded": {},
    # "test_reduce_l1_default_axes_keepdims_random": {},
    # "test_reduce_l1_default_axes_keepdims_random_expanded": {},
    # "test_reduce_l1_do_not_keepdims_example": {},
    # "test_reduce_l1_do_not_keepdims_example_expanded": {},
    # "test_reduce_l1_do_not_keepdims_random": {},
    # "test_reduce_l1_do_not_keepdims_random_expanded": {},
    # "test_reduce_l1_empty_set": {},
    # "test_reduce_l1_empty_set_expanded": {},
    # "test_reduce_l1_keep_dims_example": {},
    # "test_reduce_l1_keep_dims_example_expanded": {},
    # "test_reduce_l1_keep_dims_random": {},
    # "test_reduce_l1_keep_dims_random_expanded": {},
    # "test_reduce_l1_negative_axes_keep_dims_example": {},
    # "test_reduce_l1_negative_axes_keep_dims_example_expanded": {},
    # "test_reduce_l1_negative_axes_keep_dims_random": {},
    # "test_reduce_l1_negative_axes_keep_dims_random_expanded": {},

    # These tests fail, because the `axes` are dynamic and contain no data at runtime. Converter cannot detect this
    #  edge case, so only a warning is printed.
    # "test_reduce_l2_default_axes_keepdims_example": {},
    # "test_reduce_l2_default_axes_keepdims_example_expanded": {},
    # "test_reduce_l2_default_axes_keepdims_random": {},
    # "test_reduce_l2_default_axes_keepdims_random_expanded": {},
    "test_reduce_l2_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_do_not_keepdims_example_expanded": {},
    "test_reduce_l2_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_do_not_keepdims_random_expanded": {},
    "test_reduce_l2_empty_set": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_empty_set_expanded": {},
    "test_reduce_l2_keep_dims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_keep_dims_example_expanded": {},
    "test_reduce_l2_keep_dims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_keep_dims_random_expanded": {},
    "test_reduce_l2_negative_axes_keep_dims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_negative_axes_keep_dims_example_expanded": {},
    "test_reduce_l2_negative_axes_keep_dims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_l2_negative_axes_keep_dims_random_expanded": {},

    # "test_reduce_log_sum_asc_axes": {},
    # "test_reduce_log_sum_asc_axes_expanded": {},
    # "test_reduce_log_sum_default": {},
    # "test_reduce_log_sum_default_expanded": {},
    # "test_reduce_log_sum_desc_axes": {},
    # "test_reduce_log_sum_desc_axes_expanded": {},
    # "test_reduce_log_sum_empty_set": {},
    # "test_reduce_log_sum_empty_set_expanded": {},
    # "test_reduce_log_sum_exp_default_axes_keepdims_example": {},
    # "test_reduce_log_sum_exp_default_axes_keepdims_example_expanded": {},
    # "test_reduce_log_sum_exp_default_axes_keepdims_random": {},
    # "test_reduce_log_sum_exp_default_axes_keepdims_random_expanded": {},
    # "test_reduce_log_sum_exp_do_not_keepdims_example": {},
    # "test_reduce_log_sum_exp_do_not_keepdims_example_expanded": {},
    # "test_reduce_log_sum_exp_do_not_keepdims_random": {},
    # "test_reduce_log_sum_exp_do_not_keepdims_random_expanded": {},
    # "test_reduce_log_sum_exp_empty_set": {},
    # "test_reduce_log_sum_exp_empty_set_expanded": {},
    # "test_reduce_log_sum_exp_keepdims_example": {},
    # "test_reduce_log_sum_exp_keepdims_example_expanded": {},
    # "test_reduce_log_sum_exp_keepdims_random": {},
    # "test_reduce_log_sum_exp_keepdims_random_expanded": {},
    # "test_reduce_log_sum_exp_negative_axes_keepdims_example": {},
    # "test_reduce_log_sum_exp_negative_axes_keepdims_example_expanded": {},
    # "test_reduce_log_sum_exp_negative_axes_keepdims_random": {},
    # "test_reduce_log_sum_exp_negative_axes_keepdims_random_expanded": {},
    # "test_reduce_log_sum_negative_axes": {},
    # "test_reduce_log_sum_negative_axes_expanded": {},

    "test_reduce_max_bool_inputs": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: conversion_impossible('Conversion of ONNX `ReduceMax` with type BOOL is not possible.')
    },
    "test_reduce_max_default_axes_keepdim_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_default_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_negative_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_max_negative_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},

    # These 2 tests fail, because the `axes` are dynamic and contain no data at runtime. Converter cannot detect this
    #  edge case, so only a warning is printed.
    # "test_reduce_mean_default_axes_keepdims_example": {},
    # "test_reduce_mean_default_axes_keepdims_random": {},
    "test_reduce_mean_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_mean_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_mean_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_mean_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_mean_negative_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_mean_negative_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_reduce_min_bool_inputs": {},
    "test_reduce_min_default_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_default_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # This test fails, because the `axes` are dynamic and contain no data at runtime. Converter cannot detect this
    #  edge case, so only a warning is printed.
    # "test_reduce_min_empty_set": {},
    "test_reduce_min_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_negative_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_min_negative_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},

    "test_reduce_prod_default_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_default_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_empty_set": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_negative_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_prod_negative_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},

    # These 2 tests fail, because the `axes` are dynamic and contain no data at runtime. Converter cannot detect this
    #  edge case, so only a warning is printed.
    # "test_reduce_sum_default_axes_keepdims_example": {},
    # "test_reduce_sum_default_axes_keepdims_random": {},
    "test_reduce_sum_do_not_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_do_not_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_empty_axes_input_noop": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_empty_axes_input_noop_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_empty_set": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # This test fails, because the `axes` are dynamic and contain no data at runtime. Converter cannot detect this
    #  edge case, so only a warning is printed.
    # "test_reduce_sum_empty_set_non_reduced_axis_zero": {},
    "test_reduce_sum_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_negative_axes_keepdims_example": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reduce_sum_negative_axes_keepdims_random": {CONVERSION_ARGS: {"skip_shape_inference": True}},

    # "test_reduce_sum_square_default_axes_keepdims_example": {},
    # "test_reduce_sum_square_default_axes_keepdims_example_expanded": {},
    # "test_reduce_sum_square_default_axes_keepdims_random": {},
    # "test_reduce_sum_square_default_axes_keepdims_random_expanded": {},
    # "test_reduce_sum_square_do_not_keepdims_example": {},
    # "test_reduce_sum_square_do_not_keepdims_example_expanded": {},
    # "test_reduce_sum_square_do_not_keepdims_random": {},
    # "test_reduce_sum_square_do_not_keepdims_random_expanded": {},
    # "test_reduce_sum_square_empty_set": {},
    # "test_reduce_sum_square_empty_set_expanded": {},
    # "test_reduce_sum_square_keepdims_example": {},
    # "test_reduce_sum_square_keepdims_example_expanded": {},
    # "test_reduce_sum_square_keepdims_random": {},
    # "test_reduce_sum_square_keepdims_random_expanded": {},
    # "test_reduce_sum_square_negative_axes_keepdims_example": {},
    # "test_reduce_sum_square_negative_axes_keepdims_example_expanded": {},
    # "test_reduce_sum_square_negative_axes_keepdims_random": {},
    # "test_reduce_sum_square_negative_axes_keepdims_random_expanded": {},
    "test_reflect_pad": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    # "test_regex_full_match_basic": {},
    # "test_regex_full_match_email_domain": {},
    # "test_regex_full_match_empty": {},
    "test_relu": {},
    # "test_relu_expanded_ver18": {},
    # "test_reshape_allowzero_reordered": {},
    "test_reshape_extended_dims": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_negative_dim": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_negative_extended_dims": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_one_dim": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_reduced_dims": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_reordered_all_dims": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_reordered_last_dims": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_zero_and_negative_dim": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_reshape_zero_dim": {CONVERSION_ARGS: {"skip_shape_inference": True}},

    # ---- All the `Resize` tests fail for various reasons. All are correctly identified by the converter. ----
    # "test_resize_downsample_scales_cubic": {},
    # "test_resize_downsample_scales_cubic_A_n0p5_exclude_outside": {},
    # "test_resize_downsample_scales_cubic_align_corners": {},
    # "test_resize_downsample_scales_cubic_antialias": {},
    # "test_resize_downsample_scales_linear": {},
    # "test_resize_downsample_scales_linear_align_corners": {},
    # "test_resize_downsample_scales_linear_antialias": {},
    # "test_resize_downsample_scales_linear_half_pixel_symmetric": {},
    # "test_resize_downsample_scales_nearest": {},
    # "test_resize_downsample_sizes_cubic": {},
    # "test_resize_downsample_sizes_cubic_antialias": {},
    # "test_resize_downsample_sizes_linear_antialias": {},
    # "test_resize_downsample_sizes_linear_pytorch_half_pixel": {},
    # "test_resize_downsample_sizes_nearest": {},
    # "test_resize_downsample_sizes_nearest_not_larger": {},
    # "test_resize_downsample_sizes_nearest_not_smaller": {},
    # "test_resize_tf_crop_and_resize": {},
    # "test_resize_tf_crop_and_resize_axes_2_3": {},
    # "test_resize_tf_crop_and_resize_axes_3_2": {},
    # "test_resize_tf_crop_and_resize_extrapolation_value": {},
    # "test_resize_upsample_scales_cubic": {},
    # "test_resize_upsample_scales_cubic_A_n0p5_exclude_outside": {},
    # "test_resize_upsample_scales_cubic_align_corners": {},
    # "test_resize_upsample_scales_cubic_asymmetric": {},
    # "test_resize_upsample_scales_linear": {},
    # "test_resize_upsample_scales_linear_align_corners": {},
    # "test_resize_upsample_scales_linear_half_pixel_symmetric": {},
    # "test_resize_upsample_scales_nearest": {},
    # "test_resize_upsample_scales_nearest_axes_2_3": {},
    # "test_resize_upsample_scales_nearest_axes_3_2": {},
    # "test_resize_upsample_sizes_cubic": {},
    # "test_resize_upsample_sizes_nearest": {},
    # "test_resize_upsample_sizes_nearest_axes_2_3": {},
    # "test_resize_upsample_sizes_nearest_axes_3_2": {},
    # "test_resize_upsample_sizes_nearest_ceil_half_pixel": {},
    # "test_resize_upsample_sizes_nearest_floor_align_corners": {},
    # "test_resize_upsample_sizes_nearest_not_larger": {},
    # "test_resize_upsample_sizes_nearest_not_smaller": {},
    # "test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric": {},

    # "test_reversesequence_batch": {},
    # "test_reversesequence_time": {},
    # "test_rnn_seq_length": {},
    # "test_roialign_aligned_false": {},
    # "test_roialign_aligned_true": {},
    # "test_roialign_mode_max": {},
    "test_round": {},
    # "test_scan9_sum": {},
    # "test_scan_sum": {},
    # "test_scatter_elements_with_axis": {},
    # "test_scatter_elements_with_duplicate_indices": {},
    # "test_scatter_elements_with_negative_indices": {},
    # "test_scatter_elements_with_reduction_max": {},
    # "test_scatter_elements_with_reduction_min": {},
    # "test_scatter_elements_without_axis": {},
    # "test_scatter_with_axis": {},
    # "test_scatter_without_axis": {},
    "test_scatternd": {CONVERSION_ARGS: {'non_negative_indices': True}},
    "test_scatternd_add": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `ScatterND` with `reduction=add` is not yet supported.')},
    "test_scatternd_max": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `ScatterND` with `reduction=max` is not yet supported.')},
    "test_scatternd_min": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `ScatterND` with `reduction=min` is not yet supported.')},
    "test_scatternd_multiply": {
        CONVERSION_ERROR: not_implemented('Conversion of ONNX `ScatterND` with `reduction=mul` is not yet supported.')},
    # "test_sce_NCd1_mean_weight_negative_ii": {},
    # "test_sce_NCd1_mean_weight_negative_ii_expanded": {},
    # "test_sce_NCd1_mean_weight_negative_ii_log_prob": {},
    # "test_sce_NCd1_mean_weight_negative_ii_log_prob_expanded": {},
    # "test_sce_NCd1d2d3_none_no_weight_negative_ii": {},
    # "test_sce_NCd1d2d3_none_no_weight_negative_ii_expanded": {},
    # "test_sce_NCd1d2d3_none_no_weight_negative_ii_log_prob": {},
    # "test_sce_NCd1d2d3_none_no_weight_negative_ii_log_prob_expanded": {},
    # "test_sce_NCd1d2d3_sum_weight_high_ii": {},
    # "test_sce_NCd1d2d3_sum_weight_high_ii_expanded": {},
    # "test_sce_NCd1d2d3_sum_weight_high_ii_log_prob": {},
    # "test_sce_NCd1d2d3_sum_weight_high_ii_log_prob_expanded": {},
    # "test_sce_NCd1d2d3d4d5_mean_weight": {},
    # "test_sce_NCd1d2d3d4d5_mean_weight_expanded": {},
    # "test_sce_NCd1d2d3d4d5_mean_weight_log_prob": {},
    # "test_sce_NCd1d2d3d4d5_mean_weight_log_prob_expanded": {},
    # "test_sce_NCd1d2d3d4d5_none_no_weight": {},
    # "test_sce_NCd1d2d3d4d5_none_no_weight_expanded": {},
    # "test_sce_NCd1d2d3d4d5_none_no_weight_log_prob": {},
    # "test_sce_NCd1d2d3d4d5_none_no_weight_log_prob_expanded": {},
    # "test_sce_mean": {},
    # "test_sce_mean_3d": {},
    # "test_sce_mean_3d_expanded": {},
    # "test_sce_mean_3d_log_prob": {},
    # "test_sce_mean_3d_log_prob_expanded": {},
    # "test_sce_mean_expanded": {},
    # "test_sce_mean_log_prob": {},
    # "test_sce_mean_log_prob_expanded": {},
    # "test_sce_mean_no_weight_ii": {},
    # "test_sce_mean_no_weight_ii_3d": {},
    # "test_sce_mean_no_weight_ii_3d_expanded": {},
    # "test_sce_mean_no_weight_ii_3d_log_prob": {},
    # "test_sce_mean_no_weight_ii_3d_log_prob_expanded": {},
    # "test_sce_mean_no_weight_ii_4d": {},
    # "test_sce_mean_no_weight_ii_4d_expanded": {},
    # "test_sce_mean_no_weight_ii_4d_log_prob": {},
    # "test_sce_mean_no_weight_ii_4d_log_prob_expanded": {},
    # "test_sce_mean_no_weight_ii_expanded": {},
    # "test_sce_mean_no_weight_ii_log_prob": {},
    # "test_sce_mean_no_weight_ii_log_prob_expanded": {},
    # "test_sce_mean_weight": {},
    # "test_sce_mean_weight_expanded": {},
    # "test_sce_mean_weight_ii": {},
    # "test_sce_mean_weight_ii_3d": {},
    # "test_sce_mean_weight_ii_3d_expanded": {},
    # "test_sce_mean_weight_ii_3d_log_prob": {},
    # "test_sce_mean_weight_ii_3d_log_prob_expanded": {},
    # "test_sce_mean_weight_ii_4d": {},
    # "test_sce_mean_weight_ii_4d_expanded": {},
    # "test_sce_mean_weight_ii_4d_log_prob": {},
    # "test_sce_mean_weight_ii_4d_log_prob_expanded": {},
    # "test_sce_mean_weight_ii_expanded": {},
    # "test_sce_mean_weight_ii_log_prob": {},
    # "test_sce_mean_weight_ii_log_prob_expanded": {},
    # "test_sce_mean_weight_log_prob": {},
    # "test_sce_mean_weight_log_prob_expanded": {},
    # "test_sce_none": {},
    # "test_sce_none_expanded": {},
    # "test_sce_none_log_prob": {},
    # "test_sce_none_log_prob_expanded": {},
    # "test_sce_none_weights": {},
    # "test_sce_none_weights_expanded": {},
    # "test_sce_none_weights_log_prob": {},
    # "test_sce_none_weights_log_prob_expanded": {},
    # "test_sce_sum": {},
    # "test_sce_sum_expanded": {},
    # "test_sce_sum_log_prob": {},
    # "test_sce_sum_log_prob_expanded": {},
    # "test_selu": {},
    # "test_selu_default": {},
    # "test_selu_default_expanded_ver18": {},
    # "test_selu_example": {},
    # "test_selu_example_expanded_ver18": {},
    # "test_selu_expanded_ver18": {},
    # "test_sequence_insert_at_back": {},
    # "test_sequence_insert_at_front": {},
    # "test_sequence_map_add_1_sequence_1_tensor": {},
    # "test_sequence_map_add_1_sequence_1_tensor_expanded": {},
    # "test_sequence_map_add_2_sequences": {},
    # "test_sequence_map_add_2_sequences_expanded": {},
    # "test_sequence_map_extract_shapes": {},
    # "test_sequence_map_extract_shapes_expanded": {},
    # "test_sequence_map_identity_1_sequence": {},
    # "test_sequence_map_identity_1_sequence_1_tensor": {},
    # "test_sequence_map_identity_1_sequence_1_tensor_expanded": {},
    # "test_sequence_map_identity_1_sequence_expanded": {},
    # "test_sequence_map_identity_2_sequences": {},
    # "test_sequence_map_identity_2_sequences_expanded": {},
    "test_shape": {},
    "test_shape_clip_end": {},
    "test_shape_clip_start": {},
    "test_shape_end_1": {},
    "test_shape_end_negative_1": {},
    "test_shape_example": {},
    "test_shape_start_1": {},
    "test_shape_start_1_end_2": {},
    "test_shape_start_1_end_negative_1": {},
    "test_shape_start_negative_1": {},
    # "test_shrink_hard": {},
    # "test_shrink_hard_expanded_ver18": {},
    # "test_shrink_soft": {},
    # "test_shrink_soft_expanded_ver18": {},
    "test_sigmoid": {},
    "test_sigmoid_example": {},
    "test_sign": {},
    # "test_simple_rnn_batchwise": {},
    # "test_simple_rnn_defaults": {},
    # "test_simple_rnn_with_initial_bias": {},
    "test_sin": {},
    "test_sin_example": {},
    # "test_sinh": {},
    # "test_sinh_example": {},
    # "test_size": {},
    # "test_size_example": {},
    # "test_slice": {},
    # "test_slice_default_axes": {},
    # "test_slice_default_steps": {},
    # "test_slice_end_out_of_bounds": {},
    # "test_slice_neg": {},
    # "test_slice_neg_steps": {},
    # "test_slice_negative_axes": {},
    # "test_slice_start_out_of_bounds": {},
    "test_softmax_axis_0": {},
    # "test_softmax_axis_0_expanded": {},
    # "test_softmax_axis_0_expanded_ver18": {},
    "test_softmax_axis_1": {},
    # "test_softmax_axis_1_expanded": {},
    # "test_softmax_axis_1_expanded_ver18": {},
    "test_softmax_axis_2": {},
    # "test_softmax_axis_2_expanded": {},
    # "test_softmax_axis_2_expanded_ver18": {},
    "test_softmax_default_axis": {},
    # "test_softmax_default_axis_expanded": {},
    # "test_softmax_default_axis_expanded_ver18": {},
    "test_softmax_example": {},
    # "test_softmax_example_expanded": {},
    # "test_softmax_example_expanded_ver18": {},
    "test_softmax_large_number": {},
    # "test_softmax_large_number_expanded": {},
    # "test_softmax_large_number_expanded_ver18": {},
    "test_softmax_negative_axis": {},
    # "test_softmax_negative_axis_expanded": {},
    # "test_softmax_negative_axis_expanded_ver18": {},
    # "test_softplus": {},
    # "test_softplus_example": {},
    # "test_softplus_example_expanded_ver18": {},
    # "test_softplus_expanded_ver18": {},
    # "test_softsign": {},
    # "test_softsign_example": {},
    # "test_softsign_example_expanded_ver18": {},
    # "test_softsign_expanded_ver18": {},
    "test_spacetodepth": {},
    "test_spacetodepth_example": {},
    "test_split_1d_uneven_split_opset18": {},
    "test_split_2d_uneven_split_opset18": {},
    "test_split_equal_parts_1d_opset13": {},
    "test_split_equal_parts_1d_opset18": {},
    "test_split_equal_parts_2d": {},
    "test_split_equal_parts_2d_opset13": {},
    "test_split_equal_parts_default_axis_opset13": {},
    "test_split_equal_parts_default_axis_opset18": {},
    # "test_split_to_sequence_1": {},
    # "test_split_to_sequence_2": {},
    # "test_split_to_sequence_nokeepdims": {},
    "test_split_variable_parts_1d_opset13": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_split_variable_parts_1d_opset18": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_split_variable_parts_2d_opset13": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_split_variable_parts_2d_opset18": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_split_variable_parts_default_axis_opset13": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_split_variable_parts_default_axis_opset18": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_split_zero_size_splits_opset13": {},  # TFLite inference doesn't support tensors of size 0.
    # "test_split_zero_size_splits_opset18": {},  # TFLite inference doesn't support tensors of size 0.
    "test_sqrt": {},
    "test_sqrt_example": {},
    "test_squeeze": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_squeeze_negative_axes": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_stft": {},
    # "test_stft_with_window": {},
    # "test_string_concat": {},
    # "test_string_concat_broadcasting": {},
    # "test_string_concat_empty_string": {},
    # "test_string_concat_utf8": {},
    # "test_string_concat_zero_dimensional": {},
    # "test_string_split_basic": {},
    # "test_string_split_consecutive_delimiters": {},
    # "test_string_split_empty_string_delimiter": {},
    # "test_string_split_empty_tensor": {},
    # "test_string_split_maxsplit": {},
    # "test_string_split_no_delimiter": {},
    # "test_strnormalizer_export_monday_casesensintive_lower": {},
    # "test_strnormalizer_export_monday_casesensintive_nochangecase": {},
    # "test_strnormalizer_export_monday_casesensintive_upper": {},
    # "test_strnormalizer_export_monday_empty_output": {},
    # "test_strnormalizer_export_monday_insensintive_upper_twodim": {},
    # "test_strnormalizer_nostopwords_nochangecase": {},
    "test_sub": {},
    "test_sub_bcast": {},
    "test_sub_example": {},
    # "test_sub_uint8": {},
    "test_sum_example": {},
    "test_sum_one_input": {},
    "test_sum_two_inputs": {},
    # "test_tan": {},
    # "test_tan_example": {},
    "test_tanh": {},
    "test_tanh_example": {},
    # "test_tfidfvectorizer_tf_batch_onlybigrams_skip0": {},
    # "test_tfidfvectorizer_tf_batch_onlybigrams_skip5": {},
    # "test_tfidfvectorizer_tf_batch_uniandbigrams_skip5": {},
    # "test_tfidfvectorizer_tf_only_bigrams_skip0": {},
    # "test_tfidfvectorizer_tf_onlybigrams_levelempty": {},
    # "test_tfidfvectorizer_tf_onlybigrams_skip5": {},
    # "test_tfidfvectorizer_tf_uniandbigrams_skip5": {},
    # "test_thresholdedrelu": {},
    # "test_thresholdedrelu_default": {},
    # "test_thresholdedrelu_default_expanded_ver18": {},
    # "test_thresholdedrelu_example": {},
    # "test_thresholdedrelu_example_expanded_ver18": {},
    # "test_thresholdedrelu_expanded_ver18": {},
    "test_tile": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_tile_precomputed": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_top_k": {},
    # "test_top_k_negative_axis": {},
    # "test_top_k_smallest": {},
    "test_training_dropout": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_training_dropout_default": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_training_dropout_default_mask": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_training_dropout_mask": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_training_dropout_zero_ratio": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_training_dropout_zero_ratio_mask": {CONVERSION_ERROR: conversion_impossible(
        "Conversion of ONNX `Dropout` with a dynamic `training_mode` input tensor is not supported.")},
    "test_transpose_all_permutations_0": {},
    "test_transpose_all_permutations_1": {},
    "test_transpose_all_permutations_2": {},
    "test_transpose_all_permutations_3": {},
    "test_transpose_all_permutations_4": {},
    "test_transpose_all_permutations_5": {},
    "test_transpose_default": {},
    # "test_tril": {},
    # "test_tril_neg": {},
    # "test_tril_one_row_neg": {},
    # "test_tril_out_neg": {},
    # "test_tril_out_pos": {},
    # "test_tril_pos": {},
    # "test_tril_square": {},
    # "test_tril_square_neg": {},
    # "test_tril_zero": {},
    # "test_triu": {},
    # "test_triu_neg": {},
    # "test_triu_one_row": {},
    # "test_triu_out_neg_out": {},
    # "test_triu_out_pos": {},
    # "test_triu_pos": {},
    # "test_triu_square": {},
    # "test_triu_square_neg": {},
    # "test_triu_zero": {},
    # "test_unique_not_sorted_without_axis": {},
    # "test_unique_sorted_with_axis": {},
    # "test_unique_sorted_with_axis_3d": {},
    # "test_unique_sorted_with_negative_axis": {},
    # "test_unique_sorted_without_axis": {},
    "test_unsqueeze_axis_0": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_axis_1": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_axis_2": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_negative_axes": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_three_axes": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_two_axes": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_unsqueeze_unsorted_axes": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_upsample_nearest": {CONVERSION_ARGS: {"skip_shape_inference": True}, CONVERSION_ERROR: not_implemented(
        'Conversion of ONNX `Upsample` with a dynamic `scales` input is not supported.')},
    "test_where_example": {},
    "test_where_long_example": {},
    "test_wrap_pad": {
        CONVERSION_ARGS: {"skip_shape_inference": True},
        CONVERSION_ERROR: not_implemented("Conversion of ONNX 'Pad' with dynamic 'pads' input is not yet supported.")},
    "test_xor2d": {},
    "test_xor3d": {},
    "test_xor4d": {},
    "test_xor_bcast3v1d": {},
    "test_xor_bcast3v2d": {},
    "test_xor_bcast4v2d": {},
    "test_xor_bcast4v3d": {},
    "test_xor_bcast4v4d": {},
}

PYTORCH_CONVERTED = {
    # "test_AvgPool1d": {},
    # "test_AvgPool1d_stride": {},
    # "test_AvgPool2d": {},
    # "test_AvgPool2d_stride": {},
    # "test_AvgPool3d": {},
    # "test_AvgPool3d_stride": {},
    # "test_AvgPool3d_stride1_pad0_gpu_input": {},
    # "test_BatchNorm1d_3d_input_eval": {},
    # "test_BatchNorm2d_eval": {},
    # "test_BatchNorm2d_momentum_eval": {},
    # "test_BatchNorm3d_eval": {},
    # "test_BatchNorm3d_momentum_eval": {},
    "test_ConstantPad2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_dilated": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_groups": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_pad1": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_pad1size1": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_pad2": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_pad2size1": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv1d_stride": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_depthwise": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_depthwise_padded": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_depthwise_strided": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_depthwise_with_multiplier": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_dilated": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_groups": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_groups_thnn": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_no_bias": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_padding": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv2d_strided": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_dilated": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_dilated_strided": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_groups": {COMPARISON_ARGS: {"atol": 1e-7}, CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_no_bias": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_stride": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Conv3d_stride_padding": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_ConvTranspose2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_ConvTranspose2d_no_bias": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_ELU": {},
    # "test_Embedding": {},
    # "test_Embedding_sparse": {},
    # "test_GLU": {},
    # "test_GLU_dim": {},
    "test_LeakyReLU": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_LeakyReLU_with_negval": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_Linear": {},  # ONNXRT: Not implemented in ONNX Runtime
    "test_Linear_no_bias": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_log_softmax_dim3": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_log_softmax_lastdim": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_LogSoftmax": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_MaxPool1d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_MaxPool1d_stride": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_MaxPool1d_stride_padding_dilation": {
        CONVERSION_ERROR: conversion_impossible("MaxPool dilations '[10, 1]' cannot be converted to TFLite!")},
    "test_MaxPool2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_MaxPool2d_stride_padding_dilation": {
        CONVERSION_ERROR: conversion_impossible("MaxPool dilations '[10, 10]' cannot be converted to TFLite!")},
    # "test_MaxPool3d": {},
    # "test_MaxPool3d_stride": {},
    # "test_MaxPool3d_stride_padding": {},
    # "test_PReLU_1d": {},  # ONNXRT: Not supported by ONNX Runtime
    "test_PReLU_1d_multiparam": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: internal_error(
        "Failed to broadcast shapes '[2, 3, 4]' and '[3]' during PRelu conversion.")},
    # "test_PReLU_2d": {},  # ONNXRT: Not supported by ONNX Runtime
    "test_PReLU_2d_multiparam": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: internal_error(
        "Failed to broadcast shapes '[2, 3, 4, 5]' and '[3]' during PRelu conversion.")},
    # "test_PReLU_3d": {},  # ONNXRT: Not supported by ONNX Runtime
    "test_PReLU_3d_multiparam": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: internal_error(
        "Failed to broadcast shapes '[2, 3, 4, 5, 6]' and '[3]' during PRelu conversion.")},
    "test_PixelShuffle": {},
    # "test_PoissonNLLLLoss_no_reduce": {},
    "test_ReflectionPad2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_ReLU": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_ReplicationPad2d": {CONVERSION_ARGS: {"ignore_opset_version": True}, CONVERSION_ERROR: not_implemented(
        "Conversion of ONNX 'Pad' version 2 in 'edge' mode is not implemented and may not be possible!")},
    # "test_SELU": {},
    "test_Sigmoid": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Softmax": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_softmax_functional_dim3": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_softmax_lastdim": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_Softmin": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_Softplus": {},
    # "test_Softsign": {},
    "test_Tanh": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_ZeroPad2d": {CONVERSION_ARGS: {"ignore_opset_version": True}},
}

PYTORCH_OPERATOR = {
    # "test_operator_add_broadcast": {},
    # "test_operator_add_size1_broadcast": {},
    # "test_operator_add_size1_right_broadcast": {},
    # "test_operator_add_size1_singleton_broadcast": {},
    # "test_operator_addconstant": {},
    # "test_operator_addmm": {},
    # "test_operator_basic": {},
    "test_operator_chunk": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_clip": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_concat2": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_conv": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_convtranspose": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_exp": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_flatten": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_index": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_max": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_maxpool": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_min": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_operator_mm": {},
    # "test_operator_non_float_params": {},
    "test_operator_pad": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_operator_params": {},
    "test_operator_permute2": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_operator_pow": {},  # ONNXRT: Pow version 1. Not supported by ONNX Runtime.
    "test_operator_reduced_mean": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_reduced_mean_keepdim": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_operator_reduced_sum": {},
    # "test_operator_reduced_sum_keepdim": {},
    "test_operator_repeat": {},
    "test_operator_repeat_dim_overflow": {},
    # "test_operator_selu": {},
    "test_operator_sqrt": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    # "test_operator_symbolic_override": {},
    "test_operator_symbolic_override_nested": {CONVERSION_ARGS: {"ignore_opset_version": True}},
    "test_operator_view": {CONVERSION_ARGS: {"ignore_opset_version": True}},
}

SIMPLE = {
    "test_expand_shape_model1": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_expand_shape_model2": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_expand_shape_model3": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    "test_expand_shape_model4": {CONVERSION_ARGS: {"skip_shape_inference": True}},
    # "test_gradient_of_add": {},
    # "test_gradient_of_add_and_mul": {},
    # "test_sequence_model1": {},
    # "test_sequence_model2": {},
    # "test_sequence_model3": {},
    # "test_sequence_model4": {},
    # "test_sequence_model5": {},
    # "test_sequence_model6": {},
    # "test_sequence_model7": {},
    # "test_sequence_model8": {},
    # "test_shrink": {},
    "test_sign_model": {},
    "test_single_relu_model": {},
    # "test_strnorm_model_monday_casesensintive_lower": {},
    # "test_strnorm_model_monday_casesensintive_nochangecase": {},
    # "test_strnorm_model_monday_casesensintive_upper": {},
    # "test_strnorm_model_monday_empty_output": {},
    # "test_strnorm_model_monday_insensintive_upper_twodim": {},
    # "test_strnorm_model_nostopwords_nochangecase": {},
}

# Make sure you have downloaded model in advance with script "tests/download_models.py"
ONNX_ZOO_MODELS = {
    # Vision Models:
    "bvlcalexnet-7": {},
    "bvlcalexnet-8": {},
    "bvlcalexnet-9": {},
    "bvlcalexnet-12": {},
    "caffenet-7": {},
    "caffenet-8": {},
    "caffenet-9": {},
    "caffenet-12": {},
    "emotion-ferplus-7": {},
    "emotion-ferplus-8": {"atol": 3.82e-6},
    "googlenet-7": {},
    "googlenet-8": {},
    "googlenet-9": {},
    "googlenet-12": {},
    # "inception-v1-7": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-8": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-9": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-12": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    "inception-v2-7": {},
    "inception-v2-8": {},
    "inception-v2-9": {"atol": 2.6e-6},
    "mnist-7": {},
    # [AIR-10034] MatMul + Add optimization decreases error of this model
    "mnist-8": {"atol": 7.16e-06},
    "mnist-12": {},
    "rcnn-ilsvrc13-7": {},
    "rcnn-ilsvrc13-8": {},
    "rcnn-ilsvrc13-9": {},
    "ResNet101-DUC-7": {"marks": [pytest.mark.slow]},
    "ResNet101-DUC-12": {"marks": [pytest.mark.slow]},
    "resnet50-caffe2-v1-7": {"atol": 1.2e-7},
    "resnet50-caffe2-v1-8": {},
    "resnet50-caffe2-v1-9": {},
    # "shufflenet-7": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "shufflenet-8": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "shufflenet-9": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    "super-resolution-10": {'atol': 4.6e-5},
    "squeezenet1.1-7": {},
    "tinyyolov2-7": {"atol": 1.44e-5},
    "tinyyolov2-8": {"atol": 1.82e-5},
    "ultraface-version-RFB-320": {"atol": [3.0e-7, 3.6e-7]},
    "ultraface-version-RFB-640": {"atol": [1.3e-6, 2.7e-7]},
    "vgg16-7": {"atol": 8.59e-06, "marks": [pytest.mark.slow]},
    "vgg16-12": {"atol": 1.29e-05, "marks": [pytest.mark.slow]},
    "vgg16-bn-7": {"atol": 5.8e-06, "marks": [pytest.mark.slow]},
    "vgg19-7": {"atol": 1.24e-05, "marks": [pytest.mark.slow]},
    "vgg19-bn-7": {"atol": 8.59e-06, "marks": [pytest.mark.slow]},
    # [AIR-10034] MatMul + Add optimization decreases error of this model
    "vgg19-caffe2-7": {"atol": 8.8e-7, "marks": [pytest.mark.slow]},
    "vgg19-caffe2-8": {"marks": [pytest.mark.slow]},
    "vgg19-caffe2-9": {"marks": [pytest.mark.slow]},
    "yolov2-coco-9": {'atol': 5.e-5},
    "zfnet512-7": {},
    "zfnet512-8": {},
    "zfnet512-9": {},
    "zfnet512-12": {},

    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    # Outputs are logits.
    "resnet50-v1-12-int8": {"atol": 0.26, "atol_avx2": 1.90},
    "caffenet-12-int8": {"atol": 2.5e-3},
    "densenet-12-int8": {"atol": 0.68},  # Investigating the large error. Larger error on Windows.
    "efficientnet-lite4-11-int8": {"atol": 4.9e-3},
    # "inception-v1-12-int8": {},  # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX QLinearAveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides' and padding is not possible!
    "zfnet512-12-int8": {"atol": 2.4e-3},
    "bvlcalexnet-12-int8": {"atol": 1.3e-3},
    "mnist-12-int8": {},
    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    # Outputs are logits.
    "vgg16-12-int8": {"atol": 0.26, "atol_avx2": 0.8},
    "squeezenet1.0-12-int8": {"atol": 3.e-2},
    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    "ResNet101-DUC-12-int8": {"atol": 2.5e-4, "marks": [pytest.mark.slow]},
    "googlenet-12-int8": {"atol": 4.8e-5},
    "mobilenetv2-12-int8": {"atol": 1.13, "atol_avx2": 2.73},
    "emotion-ferplus-12-int8": {},
    "ultraface-version-RFB-320-int8": {"atol": [0.09, 0.034]},
}

# Make sure you have downloaded model in advance with script "tests/download_models.py"
ONNX_ZOO_MODELS_QUANTIZABLE = {
    # Vision Models:
    # "bvlcalexnet-7": {},  # QDQ: Old dropout spec error
    # "bvlcalexnet-8": {},  # QDQ: Old dropout spec error
    # "bvlcalexnet-9": {},  # QDQ: Old dropout spec error
    "bvlcalexnet-12": {"atol": 0.004, "marks": [pytest.mark.slow]},
    # "caffenet-7": {},  # QDQ: Old dropout spec error
    # "caffenet-8": {},  # QDQ: Old dropout spec error
    # "caffenet-9": {},  # QDQ: Old dropout spec error
    "caffenet-12": {"marks": [pytest.mark.slow]},
    "emotion-ferplus-7": {},
    "emotion-ferplus-8": {},
    # "googlenet-7": {}, #TODO model calibration fails
    # "googlenet-8": {}, #TODO model calibration fails
    # "googlenet-9": {}, #TODO model calibration fails
    "googlenet-12": {"atol": 0.004},
    # "inception-v1-7": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-8": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-9": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "inception-v1-12": {}, # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    "inception-v2-7": {"atol": 0.012, "marks": [pytest.mark.slow]},
    "inception-v2-8": {"atol": 0.016, "marks": [pytest.mark.slow]},
    "inception-v2-9": {"atol": 0.008, "marks": [pytest.mark.slow]},
    # Following models (mnist-*) produce zero error when running with ReferenceEvaluator and ONNX 1.16.*
    # Models must be upgraded to opset 19+ with "version_converter.convert_version(onnx_model, 20)".
    "mnist-7": {"atol": 0.014},
    "mnist-8": {"atol": 0.014},
    "mnist-12": {},
    # "rcnn-ilsvrc13-7": {},  # QDQ: Old dropout spec error
    # "rcnn-ilsvrc13-8": {},  # QDQ: Old dropout spec error
    # "rcnn-ilsvrc13-9": {},  # QDQ: Old dropout spec error
    "ResNet101-DUC-7": {"marks": [pytest.mark.slow]},
    "ResNet101-DUC-12": {"marks": [pytest.mark.slow]},
    "resnet50-caffe2-v1-7": {"atol": 0.004},
    "resnet50-caffe2-v1-8": {"atol": 0.004},
    "resnet50-caffe2-v1-9": {"atol": 0.004},
    # "shufflenet-7": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "shufflenet-8": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    # "shufflenet-9": {}, # Conversion of ONNX AveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides', 'dilations' and padding is not possible!
    "super-resolution-10": {},
    "squeezenet1.1-7": {"atol": 0.3},
    # "tinyyolov2-7": {"atol": 2.1e-5},  # QDQ: Outdated BatchNormalization
    # "tinyyolov2-8": {"atol": 2.3e-5},  # QDQ: Outdated BatchNormalization
    # "ultraface-version-RFB-320": {},  # QDQ: Old Slice spec error (shape inference error)
    # "ultraface-version-RFB-640": {},  # QDQ: Old Slice spec error (shape inference error)
    "vgg16-7": {"atol": 0.15, "marks": [pytest.mark.slow]},
    "vgg16-12": {"atol": 0.15, "marks": [pytest.mark.slow]},
    "vgg16-bn-7": {"atol": 0.47, "marks": [pytest.mark.slow]},
    "vgg19-7": {"atol": 0.25, "marks": [pytest.mark.slow]},
    "vgg19-bn-7": {"atol": 0.2, "marks": [pytest.mark.slow]},
    # [AIR-10034] MatMul + Add optimization decreases error of this model
    # "vgg19-caffe2-7": {"atol": 1.3e-6},  # Old dropout spec error
    # "vgg19-caffe2-8": {},  # QDQ: Old dropout spec error
    # "vgg19-caffe2-9": {},  # QDQ: Old dropout spec error
    "yolov2-coco-9": {'atol': 0.78},
    "zfnet512-7": {"atol": 0.004, "marks": [pytest.mark.slow]},
    "zfnet512-8": {"atol": 0.004, "marks": [pytest.mark.slow]},
    "zfnet512-9": {"atol": 0.004, "marks": [pytest.mark.slow]},
    "zfnet512-12": {"atol": 0.004, "marks": [pytest.mark.slow]},

    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    # Outputs are logits.
    # "resnet50-v1-12-int8": {"atol": 0.26, "atol_avx2": 1.90},  # QDQ: Error: two nodes with same node name
    # "caffenet-12-int8": {"atol": 2.5e-3},  # QDQ: Error: two nodes with same node name
    # "densenet-12-int8": {"atol": 0.81},  # Investigating the large error. QDQ: Error: two nodes with same node name
    # "efficientnet-lite4-11-int8": {"atol": 4.9e-3},  # QDQ: Error: two nodes with same node name
    # "inception-v1-12-int8": {},  # [Code.CONVERSION_IMPOSSIBLE] - Conversion of ONNX QLinearAveragePool with 'count_include_pad' = 0 and a specific combination of input shape, 'kernel_shape', 'strides' and padding is not possible!
    # "zfnet512-12-int8": {"atol": 2.4e-3},  # QDQ: Error: two nodes with same node name
    # "bvlcalexnet-12-int8": {"atol": 1.3e-3},  # QDQ: Error: two nodes with same node name
    # "mnist-12-int8": {}, # Model already quantized.
    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    # Outputs are logits.
    # "vgg16-12-int8": {"atol": 0.26, "atol_avx2": 0.8},  # QDQ: Error: two nodes with same node name
    # "squeezenet1.0-12-int8": {"atol": 3.e-2},  # QDQ: Error: two nodes with same node name
    # Affected by AVX2 issue (https://github.com/microsoft/onnxruntime/issues/11883#issuecomment-1159523223).
    # "ResNet101-DUC-12-int8": {"atol": 1.3e-4, "atol_avx2": 1.6e-4, "marks": [pytest.mark.slow]}, # Model already quantized.
    # "googlenet-12-int8": {"atol": 4.8e-5},  # QDQ: Error: two nodes with same node name
    # "mobilenetv2-12-int8": {"atol": 1.13, "atol_avx2": 2.73}, # Model already quantized.
    # "emotion-ferplus-12-int8": {"atol": 0.09}, # Model already quantized.
    # "ultraface-version-RFB-320-int8": {"atol": [0.08, 0.036]}, # Model already quantized.
}
